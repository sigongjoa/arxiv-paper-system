#!/usr/bin/env python3
"""
í†µí•© í”Œë«í¼ í…ŒìŠ¤íŠ¸: í¬ë¡¤ë§ -> AIë¶„ì„ -> PDFìƒì„±
"""
import sys
import os
import logging
import asyncio
import re
from datetime import datetime, timedelta
import shutil

ROOT_PATH = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, ROOT_PATH)
sys.path.insert(0, os.path.join(ROOT_PATH, 'backend'))

logging.basicConfig(level=logging.ERROR, format='%(asctime)s - %(levelname)s: %(message)s')

class IntegratedPlatformTest:
    def __init__(self):
        self.platforms = {
            '1': {'name': 'ArXiv', 'module': 'arxiv_crawler', 'class': 'ArxivCrawler'},
            '2': {'name': 'BioRxiv', 'module': 'biorxiv_crawler', 'class': 'BioRxivCrawler'},
            '3': {'name': 'PMC', 'module': 'pmc_crawler', 'class': 'PMCCrawler'},
            '4': {'name': 'PLOS', 'module': 'plos_crawler', 'class': 'PLOSCrawler'},
            '5': {'name': 'DOAJ', 'module': 'doaj_crawler', 'class': 'DOAJCrawler'},
            '6': {'name': 'CORE', 'module': 'core_crawler', 'class': 'CORECrawler'}
        }
        
        print("=== í†µí•© í”Œë«í¼ í…ŒìŠ¤íŠ¸ (í¬ë¡¤ë§->AIë¶„ì„->PDFìƒì„±) ===")
        print(f"ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
    def show_menu(self):
        print("\nì‚¬ìš© ê°€ëŠ¥í•œ í”Œë«í¼:")
        for key, platform in self.platforms.items():
            print(f"  {key}. {platform['name']}")
        print("  7. ëª¨ë“  í”Œë«í¼ í…ŒìŠ¤íŠ¸")
        print("  0. ì¢…ë£Œ")
        
    def get_crawler(self, platform_info):
        module_path = f"api.crawling.{platform_info['module']}"
        module = __import__(module_path, fromlist=[platform_info['class']])
        crawler_class = getattr(module, platform_info['class'])
        return crawler_class()

    def setup_ai_components(self):
        from agents.lm_studio_client import LMStudioClient
        from agents.multi_platform_analysis_agent import MultiPlatformAnalysisAgent
        from automation.pdf_generator import PdfGenerator
        # NotionLogger ì„í¬íŠ¸ ë° ì´ˆê¸°í™” ë¹„í™œì„±í™”
        # from utils.notion import NotionLogger 
        
        lm_client = LMStudioClient()
        analysis_agent = MultiPlatformAnalysisAgent(lm_client)
        pdf_generator = PdfGenerator()
        # notion_logger = NotionLogger() # NotionLogger ì´ˆê¸°í™” ë¹„í™œì„±í™”
        notion_logger = None # NotionLoggerë¥¼ Noneìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì‚¬ìš©í•˜ì§€ ì•Šë„ë¡ í•¨
        
        print("âœ… AI ì»´í¬ë„ŒíŠ¸ (ë©€í‹°í”Œë«í¼ + Notion ë¡œê¹…) ì´ˆê¸°í™” ì™„ë£Œ")
        return lm_client, analysis_agent, pdf_generator, notion_logger

            
    async def test_platform_integrated(self, platform_key):
        platform_info = self.platforms[platform_key]
        platform_name = platform_info['name']
        
        print(f"\n{'='*60}")
        print(f"{platform_name} í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print(f"{'='*60}")
        
        # ëŒ€ìƒ PDF ë””ë ‰í† ë¦¬ ì •ë¦¬
        self.clear_pdf_target_directory()
        
        # 1. í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
        crawler = self.get_crawler(platform_info)
        if not crawler:
            print(f"âŒ {platform_name} í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” ì‹¤íŒ¨")
            return
            
        # 2. AI ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”

        lm_client, analysis_agent, pdf_generator, notion_logger = self.setup_ai_components()
 
            
        print(f"âœ… {platform_name} ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # 3. í¬ë¡¤ë§
        print(f"\nğŸ“¡ {platform_name} í¬ë¡¤ë§ ì‹œì‘...")
        test_limit = 1
        crawling_start = datetime.now()
        
        try:
            papers = []
            if platform_name == 'ArXiv':
                categories = ['cs.AI']
                start_date = datetime.now() - timedelta(days=7)
                end_date = datetime.now()
                for i, paper in enumerate(crawler.crawl_papers(categories, start_date, end_date, test_limit)):
                    papers.append(paper)
                    if len(papers) >= test_limit:
                        break
            else:
                for i, paper in enumerate(crawler.crawl_papers(None, None, None, test_limit)):
                    papers.append(paper)
                    if len(papers) >= test_limit:
                        break
                        
            crawling_time = (datetime.now() - crawling_start).total_seconds()
            print(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ: {len(papers)}ê°œ ë…¼ë¬¸, {crawling_time:.2f}ì´ˆ")
            
            if not papers:
                print("âŒ í¬ë¡¤ë§ëœ ë…¼ë¬¸ì´ ì—†ìŒ")
                return
                
        except Exception as e:
            print(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            logging.error(f"{platform_name} í¬ë¡¤ë§ ì—ëŸ¬: {e}")
            return
            
        # 4. AI ë¶„ì„ ë° ê°œë³„ PDF ìƒì„±
        print(f"\nğŸ¤– AI ë¶„ì„ ë° PDF ìƒì„± ì‹œì‘...")
        analysis_start = datetime.now()
        
        for i, paper in enumerate(papers, 1):
            try:
                print(f"\nğŸ“„ ë…¼ë¬¸ {i}/{len(papers)} ì²˜ë¦¬ ì¤‘...")
                
                # ë…¼ë¬¸ ë©”íƒ€ë°ì´í„° ì¤€ë¹„
                paper_metadata = {
                    'id': getattr(paper, 'paper_id', f'unknown_{i}'),
                    'title': getattr(paper, 'title', 'Unknown Title'),
                    'authors': getattr(paper, 'authors', []),
                    'platform': platform_name
                }
                
                # ë…¼ë¬¸ ë‚´ìš© (ìš”ì•½ì´ë‚˜ ì´ˆë¡ ì‚¬ìš©)
                paper_content = getattr(paper, 'summary', '') or getattr(paper, 'abstract', '') or paper_metadata['title']
                
                print(f"  âš¡ ë…¼ë¬¸ {i} AI ë¶„ì„ ì¤‘...")
                # AI ë¶„ì„ ìˆ˜í–‰
                analysis_result = await analysis_agent.analyze_paper(paper_content, paper_metadata)
                
                # ë¶„ì„ ê²°ê³¼ë¥¼ PDFìš© ë°ì´í„°ë¡œ ë³€í™˜
                analyzed_paper = {
                    'paper_id': paper_metadata['id'],
                    'title': analysis_result.title,
                    'authors': paper_metadata['authors'],
                    'categories': getattr(paper, 'categories', [platform_name]),
                    'summary': analysis_result.summary,
                    'key_insights': analysis_result.key_insights,
                    'methodology': analysis_result.methodology,
                    'main_findings': analysis_result.main_findings,
                    'limitations': analysis_result.limitations,
                    'future_work': analysis_result.future_work,
                    'keywords': analysis_result.technical_keywords,
                    'confidence_score': analysis_result.confidence_score,
                    'platform': platform_name,
                    'pdf_url': getattr(paper, 'pdf_url', ''),
                    'published_date': getattr(paper, 'published_date', '')
                }
                
                print(f"  âœ… ë…¼ë¬¸ {i} ë¶„ì„ ì™„ë£Œ (ì‹ ë¢°ë„: {analysis_result.confidence_score:.2f})")
                
                # Notionì— ë¶„ì„ ê²°ê³¼ ë¡œê¹… (ë¹„í™œì„±í™”)
                # try:
                #     if notion_logger:
                #         notion_logger.log_analysis_result(analysis_result)
                #         print(f"  ğŸ“ ë…¼ë¬¸ {i} ë¶„ì„ ê²°ê³¼ Notion ë¡œê¹… ì™„ë£Œ")
                # except Exception as e:
                #     print(f"  âš ï¸ ë…¼ë¬¸ {i} Notion ë¡œê¹… ì‹¤íŒ¨: {e}")
                
                # ì¦‰ì‹œ ê°œë³„ PDF ìƒì„±
                print(f"  ğŸ“„ ë…¼ë¬¸ {i} PDF ìƒì„± ì¤‘...")
                pdf_start = datetime.now()
                
                try:
                    # íŒŒì¼ëª…ì— ì‚¬ìš©ë  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±° ë° ê³µë°±ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ëŒ€ì²´
                    safe_title = re.sub(r'[\/:*?"<>|]', '', analysis_result.title).replace(' ', '_')
                    # PDF íŒŒì¼ëª…ìœ¼ë¡œ ë…¼ë¬¸ ì œëª© ì‚¬ìš©
                    pdf_title = safe_title
                    pdf_bytes = pdf_generator.generate_from_papers([analyzed_paper], pdf_title)
                    
                    pdf_time = (datetime.now() - pdf_start).total_seconds()
                    print(f"  âœ… ë…¼ë¬¸ {i} PDF ìƒì„± ì™„ë£Œ: output/pdfs/{safe_title}.pdf ({pdf_time:.2f}ì´ˆ)") # ì¶œë ¥ ë©”ì‹œì§€ ìˆ˜ì •
                    
                    # Notionì— PDF ìƒì„± ê²°ê³¼ ë¡œê¹… (ë¹„í™œì„±í™”)
                    # try:
                    #     if notion_logger:
                    #         notion_logger.log_pdf_generation(analyzed_paper, "PDF ìƒì„± ì„±ê³µ")
                    #         print(f"  ğŸ“ ë…¼ë¬¸ {i} PDF ìƒì„± ê²°ê³¼ Notion ë¡œê¹… ì™„ë£Œ")
                    # except Exception as e:
                    #     print(f"  âš ï¸ ë…¼ë¬¸ {i} PDF Notion ë¡œê¹… ì‹¤íŒ¨: {e}")
                    
                except Exception as e:
                    print(f"  âŒ ë…¼ë¬¸ {i} PDF ìƒì„± ì‹¤íŒ¨: {e}")
                    logging.error(f"ë…¼ë¬¸ {i} PDF ìƒì„± ì—ëŸ¬: {e}")
                    
                    # PDF ìƒì„± ì‹¤íŒ¨ë„ Notionì— ë¡œê¹… (ë¹„í™œì„±í™”)
                    # try:
                    #     if notion_logger:
                    #         notion_logger.log_pdf_generation(analyzed_paper, "PDF ìƒì„± ì‹¤íŒ¨", str(e))
                    # except:
                    #     pass
                    continue
                
            except Exception as e:
                print(f"  âŒ ë…¼ë¬¸ {i} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                logging.error(f"ë…¼ë¬¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
                
        analysis_time = (datetime.now() - analysis_start).total_seconds()
        print(f"âœ… ëª¨ë“  ë…¼ë¬¸ ì²˜ë¦¬ ì™„ë£Œ: {analysis_time:.2f}ì´ˆ")
            
        # 6. ê²°ê³¼ ìš”ì•½
        total_time = (datetime.now() - crawling_start).total_seconds()
        print(f"\nğŸ“Š {platform_name} í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ:")
        print(f"   â€¢ í¬ë¡¤ë§: {len(papers)}ê°œ ë…¼ë¬¸")
        print(f"   â€¢ ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ")
        print(f"   â€¢ ê°œë³„ PDF ìƒì„± ì™„ë£Œ")
            
    async def test_all_platforms_integrated(self):
        print(f"\n{'='*80}")
        print("ëª¨ë“  í”Œë«í¼ í†µí•© í…ŒìŠ¤íŠ¸")
        print(f"{'='*80}")
        
        results = {}
        total_start = datetime.now()
        
        for key, platform_info in self.platforms.items():
            platform_name = platform_info['name']
            await self.test_platform_integrated(key)
            results[platform_name] = 'SUCCESS'

                
        total_duration = (datetime.now() - total_start).total_seconds()
        
        print(f"\n{'='*80}")
        print("ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print(f"{'='*80}")
        print(f"ì´ ì†Œìš” ì‹œê°„: {total_duration:.2f}ì´ˆ")
        
        for platform, result in results.items():
            status = "âœ…" if result == 'SUCCESS' else "âŒ"
            print(f"{status} {platform}: {result}")
            
    def run(self):
        while True:
            self.show_menu()
            
            try:
                choice = input("\nì„ íƒí•˜ì„¸ìš” (0-7): ").strip()
                
                if choice == '0':
                    print("í†µí•© í…ŒìŠ¤íŠ¸ ë„êµ¬ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                elif choice == '7':
                    asyncio.run(self.test_all_platforms_integrated())
                elif choice in self.platforms:
                    asyncio.run(self.test_platform_integrated(choice))
                else:
                    print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    
            except KeyboardInterrupt:
                print("\n\ní…ŒìŠ¤íŠ¸ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
                logging.error(f"ë©”ì¸ ë£¨í”„ ì—ëŸ¬: {e}")

    def clear_pdf_target_directory(self):
        target_dir = os.path.join(ROOT_PATH, "pdfs")
        if os.path.exists(target_dir):
            for filename in os.listdir(target_dir):
                file_path = os.path.join(target_dir, filename)
                try:
                    if os.path.isfile(file_path) or os.path.islink(file_path):
                        os.unlink(file_path)
                    elif os.path.isdir(file_path):
                        shutil.rmtree(file_path)
                    logging.error(f"Cleared old PDF: {file_path}")
                except Exception as e:
                    logging.error(f"Failed to delete {file_path}. Reason: {e}")
        else:
            os.makedirs(target_dir, exist_ok=True)
        logging.error(f"PDF target directory {target_dir} cleared or created.")

def main():
    try:
        tester = IntegratedPlatformTest()
        tester.run()
    except Exception as e:
        print(f"âŒ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
        logging.error(f"ë©”ì¸ í•¨ìˆ˜ ì—ëŸ¬: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
